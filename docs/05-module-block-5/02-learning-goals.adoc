=== {learning-goals}


// tag::DE[]
[[LZ-5-1]]
==== LZ 5-1 - Speichersysteme
Die Teilnehmer:innen kennen die folgenden wesentlichen Systeme zum Speichern digitaler Daten und können die jeweiligen Besonderheiten erläutern:

- Filesystem
- Block-Storage System
- Objekt-Storage System

Die Teilnehmer:innen kennen spezielle Kriterien zur Auswahl des passenden Systems für große Datenmengen, wie etwa

- Performanz - Zugriffszeit (Latency), Durchsatz (Throughput)
- Skalierbarkeit
- Kapazität
- Kosten

Die Teilnehmer:innen wissen, dass Speichersysteme unterschiedlich an Systeme zur Verarbeitung der Daten angebunden werden können:

- Direkte Anbindung (Direct Attached Storage - DAS)
- Speichernetzwerk (Storage-Area-Network - SAN)
- Netzwerkspeicher (Network Attached Storage - NAS)

Die Teilnehmer:innen kennen die Vor- und Nachteile des jeweiligen Ansatzes.

[[LZ-5-2]]
==== LZ 5-2 - Datenbanksysteme
Die Teilnehmer:innen verstehen, dass die Verwaltung von Daten Aufgaben umfasst, die von Speichersystemen nicht direkt unterstützt werden, wie etwa

- Verwaltung der Metadaten zu den Daten
- Vorgabe und Anwendung von Schema-Informationen zu den Daten
- Sicherstellen der Konsistenz der Daten
- Validierung von Daten
- Redundante Datenhaltung speziell für verbesserte Verfügbarkeit und Zugriffszeiten
- Standardisierte, flexible und performante Datenzugriffe
- Feingranulare Zugriffskontrolle
- Skalierbarkeit
- Optimierung (Reduzierung) der Speichernutzung

Die Teilnehmer:innen wissen, dass Datenbanksysteme (DBS) diese Aufgaben übernehmen. Sie verstehen, dass DBS auf der Basis aller Speichersysteme umgesetzt werden können. Sie kennen die folgenden Typen von DBS und sind mit den jeweiligen Besonderheiten vertraut:

- Relationale DBS
- NoSQL DBS
- Key-Value DBS
- (Wide) Column DBS
- Document DBS
- Graph DBS

Die Teilnehmer:innen kennen entsprechende Produkte zu diesen DBS-Typen und ihnen ist bewusst, dass Produkte auch mehrere dieser Typen abbilden können.

[[LZ-5-3]]
==== LZ 5-3 - Datenbanksysteme für analytische Anwendungen

Die Teilnehmer:innen kennen Systeme, die für spezielle Anwendungsfälle mit großen Datenmengen optimiert sind:

- Searchengines
- Timeseries DBS
- Multidimensionale DBS / Data Marts / Cubes
- In-Memory DBS
- Event Store DBS
- Vector DBS
- Stream Storage

Die Teilnehmer:innen verstehen, dass einige o.g. Aufgaben alleine durch die Verwendung geeigneter Datei- oder Tabellenformate abgedeckt werden können. Sie kennen speziell die folgenden Formate:

- Dateiformate: Avro, ORC, Parquet
- Tabellenformate (Open Table Formats): Delta, Iceberg, Hudi

[[LZ-5-4]]
==== LZ 5-4 - Concurrency Control
Die Teilnehmer:innen verstehen, dass bei Multi-Threading und -Processing Systemen mit nebenläufiger Verarbeitung sowie redundanter Speicherung von Daten die Konsistenz von Daten explizit sichergestellt werden muss. Ihnen ist das Konzept von ACID Transaktionen und deren Serialisierbarkeit vertraut. Sie wissen, dass ACID Transaktionen auf unterschiedliche Weisen und mit unterschiedlichen Garantien für Konsistenz (Consistency) und Isolation umgesetzt werden können.

Die Teilnehmer:innen wissen, dass ACID Transaktionen üblicherweise von (relationalen) Datenbankmanagementsystemen zur Verfügung gestellt werden, dass sie aber nicht auf diese Systeme beschränkt sind.

Den Teilnehmer:innen ist das alternative Konzept der BASE-Transaktionen sowie speziell der eventuellen Konsistenz (Eventual Consistency) verteilter Anwendungen vertraut.

Die Teilnehmer:innen verstehen, dass es bei der Verarbeitung großer Datenmengen (speziell im Batch) sinnvoll sein kann, auf ACID Transaktionen zu verzichten oder sie zumindest mit schwächeren Garantien für Consistency und Isolation zu verwenden um die Verarbeitungsgeschwindigkeit zu verbessern. Sie verstehen, dass beim Einsatz von Streaming Systemen eine nebenläufige Verarbeitung stattfindet, bei der der Einsatz von Transaktionen sinnvoll sein kann.

[[LZ-5-5]]
==== LZ 5-5 - Versionierung von Daten
Den Teilnehmer:innen ist bewusst, dass bei veränderlichen Daten nicht nur der aktuelle Zustand, sondern auch die früheren Zustände (speziell für analytische Auswertungen) von Interesse sein können. Sie kennen die folgenden Verfahren für die Versionierung von Daten und verstehen, wie diese etwa in Form von Datenbanksystemen mit den o.g. Speichersystemen kombiniert werden:

- Transaktionen (über die Serialisierbarkeit)
- Versionskontrolle
- Event-Sourcing

[[LZ-5-6]]
==== LZ 5-6 - Optimierung und Skalierung
Die Teilnehmer:innen kennen übliche Verfahren, um Speichersysteme bei steigender Last zu optimieren und zu skalieren, wie etwa

- Sharding
- Partitionierung (vertikal/horizontal)
- Indexierung
- Reflections
- Caching
- Append Only / Read Only
- Blockierender vs. nicht-blockierender Zugriff

Die Teilnehmer:innen wissen, dass es bei größeren Datenmengen vorteilhaft und notwendig ist die Daten auf mehreren Servern zu verteilen. Sie wissen dabei, dass mehrere Server sowohl das Speichern, Abrufen und Verarbeiten der Daten schneller macht als auch eine Redundanz der Daten bereitstellt, falls ein Server ausfällt.

Die Teilnehmer:innen verstehen, dass Daten oft nicht unbefristet aufbewahrt werden können. Sie kennen Ansätze für Data Retention, wie:

- Wahl der Speichertechnologie abhängig von der Häufigkeit des Datenzugriffs  ("Hot" und "Cold" Storage)
- Automatisches Löschen von Daten nach vorgebenen Kriterien, z.B. Ablauf einer Speicherfrist

[[LZ-5-7]]
==== LZ 5-7 - Datenmodelle für analytische Daten
Den Teilnehmer:innen ist der Umgang mit Datenmodellen generell vertraut. Sie verstehen, wie Datenmodelle für die Arbeit mit analytischen Daten sich sowohl an den Datenmodellen der Quellsysteme als auch an den Anforderungen an die Datenanalyse orientieren müssen.

Die Teilnehmer:innen kennen das Konzept der Normalisierung von Datenmodellen. Sie verstehen, dass für die Arbeit mit analytischen Daten häufig auf die für operative Daten übliche Normalisierung verzichtet wird und vorrangig denormaliserte Datenmodelle in diesem Umfeld verwendet werden.

Die Teilnehmer:innen verstehen, dass Datenmodelle sowohl im Hinblick auf die verwendeten Quellsysteme als auch, noch weit deutlicher, im Hinblick auf die analytischen Anwendungen, Änderungen unterworfen sind. Sie kennen Ansätze, wie mit entsprechenden Änderungen umgegangen werden kann, wie etwa

- Verwendung multidimensionaler Datenmodelle (Star, Snowflake, Data Vault)
- Zerlegung in Teil-Modelle (siehe <<LZ-10-2>> - Domain Ownership)
- Automatisierung der Modell-Änderungen (DWH Automation)

[[LZ-5-8]]
==== LZ 5-8 - Data Warehouse und Data Lake
Die Teilnehmer:innen wissen, dass Data Warehouses und Data Lakes Ansätze sind, um Daten aus verschiedenen Quellsystemen zusammenführen und um einen vereinheitlichten Zugriff auf diese Daten bieten zu können. Sie wissen, dass die beiden Ansätze für OLAP Anwendungen optimiert sind.

Die Teilnehmer:innen wissen, wie Speichersysteme und darauf aufbauende Datenbanksysteme als Grundlage für DWH und DL Systeme verwendet werden.

Die Teilnehmer:innen kennen wesentliche Unterschiede zwischen DWH und DL Systemen, wie etwa

- Ein definiertes Schema (Schema on Write) beim DWH (das sich im Laufe der Zeit ändern kann) gegenüber mehreren parallelen Schemata (etwa mit Schema on Read) beim DL.
- Nur vereinheitlichte Daten im DWH während im DL auch die ursprünglichen Quelldaten (Rohdaten) vorgehalten werden.
- Die bessere Eignung von Data Lakes für Künstliche Intelligenz und Machine Learning Szenarien, da dort noch die ursprünglichen Quelldaten vorhanden sind
- Optimierte Strukturen für den lesenden (analytischen) Zugriff beim DWH gegenüber vereinfachten schreibenden Zugriffen beim DL.
- Begrenzung auf strukturierte Daten beim DWH während DL auch unstrukturierte und semi-strukturierte Daten aufnehmen können.
- Hoher Aufwand für die Integration neuer Datenquellen beim DWH während neue Datenquellen in den DL direkt aufgenommen werden können.
- Hoher Aufwand für die Vereinheitlichung von Daten beim lesenden (analytischen) Zugriff im DL während dies beim DWH in deutlich geringerem Umfang erforderlich ist.

Die Teilnehmer:innen kennen Lösungsansätze, um in DL Systemen den Aufwand für die Vereinheitlichung beim lesenden Zugriff zu reduzieren:

- Aufteilen des DL in Bereiche unterschiedlicher Datenqualität – etwa Bronze, Silber und Gold –, wobei die Rohdaten im Bronze-Bereich und die vereinheitlichten, gut analysierbaren Daten im Gold-Bereich zu finden sind  (Data Lakehouse).
- Technische Aspekte der Vereinheitlichung direkt bei der Eingangsverarbeitung erledigen (einheitliche Zeichensätze, Null-Values, Datumsformate, ...)
- Modularisierung des DL etwa über die Verwendung von DDD.

// end::DE[]

// tag::EN[]
[[LG-5-1]]
==== LG 5-1: Storage systems
tbd.

[[LG-5-2]]
==== LG 5-2: Database systems
tbd.

[[LG-5-3]]
==== LG 5-3: Database systems for analytical applications
tbd.

[[LG-5-4]]
==== LG 5-4: Concurrency Control
tbd.

[[LG-5-5]]
==== LG 5-5: Versioning of data
tbd.

[[LG-5-6]]
==== LG 5-6: Optimization and scaling
tbd.

[[LG-5-7]]
==== LG 5-7: Data models for analytical data
tbd.

[[LG-5-8]]
==== LG 5-8: Data Warehouse and Data Lake
tbd.

// end::EN[]
